{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from DataPlug import DataPlug as dp\n",
    "from SqueezeNet import SqueezeNet as sq\n",
    "\n",
    "# Util Imports\n",
    "import time # timer for sentiment analysis\n",
    "from tqdm import tqdm # progress bar for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "squeeze = sq(\"SqueezeNet\")\n",
    "dataPlug = dp(\"DataPlug\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     title  score  \\\n0                                Whats going on with PLTR?      1   \n1        Need explanations on Level 2 data for GME, why...      1   \n2             XRT is being used as a laundry short machine      1   \n3                                                Airlines?      1   \n4                                               Buy TRXC ðŸš€      1   \n...                                                    ...    ...   \n1118858  EBAY posts higher 1Q net income and revenue, s...      7   \n1118859  Anyone betting on VVUS and their potential app...      1   \n1118860  My poorly timed opening position for AAPL earn...     12   \n1118861         GOOG - beat estimates, price barely rises.      2   \n1118862         Earnings season is here.  Place your bets.     13   \n\n         num_comments  timestamp  \n0                   2 2021-02-16  \n1                   2 2021-02-16  \n2                   2 2021-02-16  \n3                   2 2021-02-16  \n4                   2 2021-02-16  \n...               ...        ...  \n1118858             4 2012-04-19  \n1118859             0 2012-04-17  \n1118860            21 2012-04-16  \n1118861             0 2012-04-12  \n1118862            22 2012-04-11  \n\n[1118863 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Whats going on with PLTR?</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Need explanations on Level 2 data for GME, why...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XRT is being used as a laundry short machine</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Airlines?</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Buy TRXC ðŸš€</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1118858</th>\n      <td>EBAY posts higher 1Q net income and revenue, s...</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2012-04-19</td>\n    </tr>\n    <tr>\n      <th>1118859</th>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2012-04-17</td>\n    </tr>\n    <tr>\n      <th>1118860</th>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>12</td>\n      <td>21</td>\n      <td>2012-04-16</td>\n    </tr>\n    <tr>\n      <th>1118861</th>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2012-04-12</td>\n    </tr>\n    <tr>\n      <th>1118862</th>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>13</td>\n      <td>22</td>\n      <td>2012-04-11</td>\n    </tr>\n  </tbody>\n</table>\n<p>1118863 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/r_wallstreetbets_posts.csv', dtype={'id': 'str', 'title': 'str', 'score': 'int', 'author': 'str','author_flair_text': 'str','removed_by': 'str', 'total_awards_received': 'str','awarders': 'str','created_utc': 'int', 'full_link': 'str', 'num_comments': 'int', 'over_18': 'bool'})\n",
    "# convert utc time to datetime\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df['timestamp'] = df['created_utc'].astype('datetime64[ns]').dt.floor('D')\n",
    "\n",
    "df.drop('author', inplace=True, axis=1)\n",
    "df.drop('created_utc', inplace=True, axis=1)\n",
    "df.drop('id', inplace=True, axis=1)\n",
    "df.drop('author_flair_text', inplace=True, axis=1)\n",
    "df.drop('removed_by', inplace=True, axis=1)\n",
    "df.drop('awarders', inplace=True, axis=1)\n",
    "df.drop('full_link', inplace=True, axis=1)\n",
    "df.drop('over_18', inplace=True, axis=1)\n",
    "df.drop('total_awards_received', inplace=True, axis=1)\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: str(x))\n",
    "\n",
    "display(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agg_func = {'title': list, 'score': 'mean', 'num_comments': 'mean'}\n",
    "\n",
    "# Replace NaN values with 'NaN'\n",
    "#df['total_awards_received'] = df['total_awards_received'].fillna(0)\n",
    "# Group by date and aggregate\n",
    "df_new = df.groupby(df['timestamp']).aggregate(agg_func)\n",
    "display(df_new)\n",
    "# Join lists of titles, ids, urls, and bodies into one string per date to perform sentiment analysis.\n",
    "\n",
    "df_new['title'] = df_new['title'].apply(lambda x: '||'.join(x))\n",
    "\n",
    "\n",
    "display(df_new)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title           1015951\n",
      "score              3385\n",
      "num_comments       2913\n",
      "timestamp          3020\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     title  score  \\\n0                                Whats going on with PLTR?      1   \n1        Need explanations on Level 2 data for GME, why...      1   \n2             XRT is being used as a laundry short machine      1   \n3                                                Airlines?      1   \n4                                               Buy TRXC ðŸš€      1   \n...                                                    ...    ...   \n1118858  EBAY posts higher 1Q net income and revenue, s...      7   \n1118859  Anyone betting on VVUS and their potential app...      1   \n1118860  My poorly timed opening position for AAPL earn...     12   \n1118861         GOOG - beat estimates, price barely rises.      2   \n1118862         Earnings season is here.  Place your bets.     13   \n\n         num_comments  timestamp  \n0                   2 2021-02-16  \n1                   2 2021-02-16  \n2                   2 2021-02-16  \n3                   2 2021-02-16  \n4                   2 2021-02-16  \n...               ...        ...  \n1118858             4 2012-04-19  \n1118859             0 2012-04-17  \n1118860            21 2012-04-16  \n1118861             0 2012-04-12  \n1118862            22 2012-04-11  \n\n[1118863 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Whats going on with PLTR?</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Need explanations on Level 2 data for GME, why...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XRT is being used as a laundry short machine</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Airlines?</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Buy TRXC ðŸš€</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1118858</th>\n      <td>EBAY posts higher 1Q net income and revenue, s...</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2012-04-19</td>\n    </tr>\n    <tr>\n      <th>1118859</th>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2012-04-17</td>\n    </tr>\n    <tr>\n      <th>1118860</th>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>12</td>\n      <td>21</td>\n      <td>2012-04-16</td>\n    </tr>\n    <tr>\n      <th>1118861</th>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2012-04-12</td>\n    </tr>\n    <tr>\n      <th>1118862</th>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>13</td>\n      <td>22</td>\n      <td>2012-04-11</td>\n    </tr>\n  </tbody>\n</table>\n<p>1118863 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataPlug.df = df\n",
    "\n",
    "print(dataPlug.df.nunique())\n",
    "\n",
    "display(dataPlug.df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      timestamp       Open       High      Low    Close  Adj Close     Volume\n0    2012-04-11   5.330000   5.380000   5.2350   5.3175   3.603972   19562000\n1    2012-04-12   5.325000   5.427500   5.3125   5.3900   3.653110    8414800\n2    2012-04-13   5.375000   5.375000   5.2800   5.3075   3.597196    8956000\n3    2012-04-16   5.325000   5.452500   5.2425   5.4250   3.676833   13710000\n4    2012-04-17   5.455000   5.550000   5.4500   5.5375   3.753081   16022400\n...         ...        ...        ...      ...      ...        ...        ...\n2221 2021-02-08  18.102501  18.165001  14.5050  15.0000  15.000000  102749200\n2222 2021-02-09  14.152500  14.250000  11.6300  12.5775  12.577500  107372400\n2223 2021-02-10  12.692500  15.707500  11.6375  12.8000  12.800000  145820000\n2224 2021-02-11  12.502500  13.830000  12.0550  12.7750  12.775000   52226800\n2225 2021-02-12  12.687500  13.810000  12.0125  13.1000  13.100000   58293200\n\n[2226 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-04-11</td>\n      <td>5.330000</td>\n      <td>5.380000</td>\n      <td>5.2350</td>\n      <td>5.3175</td>\n      <td>3.603972</td>\n      <td>19562000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-04-12</td>\n      <td>5.325000</td>\n      <td>5.427500</td>\n      <td>5.3125</td>\n      <td>5.3900</td>\n      <td>3.653110</td>\n      <td>8414800</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-04-13</td>\n      <td>5.375000</td>\n      <td>5.375000</td>\n      <td>5.2800</td>\n      <td>5.3075</td>\n      <td>3.597196</td>\n      <td>8956000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-04-16</td>\n      <td>5.325000</td>\n      <td>5.452500</td>\n      <td>5.2425</td>\n      <td>5.4250</td>\n      <td>3.676833</td>\n      <td>13710000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-04-17</td>\n      <td>5.455000</td>\n      <td>5.550000</td>\n      <td>5.4500</td>\n      <td>5.5375</td>\n      <td>3.753081</td>\n      <td>16022400</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2221</th>\n      <td>2021-02-08</td>\n      <td>18.102501</td>\n      <td>18.165001</td>\n      <td>14.5050</td>\n      <td>15.0000</td>\n      <td>15.000000</td>\n      <td>102749200</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>2021-02-09</td>\n      <td>14.152500</td>\n      <td>14.250000</td>\n      <td>11.6300</td>\n      <td>12.5775</td>\n      <td>12.577500</td>\n      <td>107372400</td>\n    </tr>\n    <tr>\n      <th>2223</th>\n      <td>2021-02-10</td>\n      <td>12.692500</td>\n      <td>15.707500</td>\n      <td>11.6375</td>\n      <td>12.8000</td>\n      <td>12.800000</td>\n      <td>145820000</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>2021-02-11</td>\n      <td>12.502500</td>\n      <td>13.830000</td>\n      <td>12.0550</td>\n      <td>12.7750</td>\n      <td>12.775000</td>\n      <td>52226800</td>\n    </tr>\n    <tr>\n      <th>2225</th>\n      <td>2021-02-12</td>\n      <td>12.687500</td>\n      <td>13.810000</td>\n      <td>12.0125</td>\n      <td>13.1000</td>\n      <td>13.100000</td>\n      <td>58293200</td>\n    </tr>\n  </tbody>\n</table>\n<p>2226 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPlug.get_price_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "dataPlug.merge_dataframes()\n",
    "\n",
    "\n",
    "display(dataPlug.mergedDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataPlug.df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 57953/1118863 [00:04<01:15, 13970.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 19\u001B[0m\n\u001B[0;32m     15\u001B[0m text \u001B[38;5;241m=\u001B[39m dataPlug\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m][i]\n\u001B[0;32m     16\u001B[0m clean_text \u001B[38;5;241m=\u001B[39m squeeze\u001B[38;5;241m.\u001B[39mclean_text(text)\n\u001B[1;32m---> 19\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43msqueeze\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentiment_analysis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclean_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Add scores to array\u001B[39;00m\n\u001B[0;32m     21\u001B[0m positive\u001B[38;5;241m.\u001B[39mappend(score[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpos\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\Documents\\Abroad Classes\\Computational Analysis of Big Data\\SqueezeNet\\src\\SqueezeNet.py:59\u001B[0m, in \u001B[0;36mSqueezeNet.sentiment_analysis\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03m\"\"\"A function to perform sentiment analysis with vaderSentiment\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m:params: text: text to perform sentiment analysis on\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[38;5;124;03m:returns: score: the sentiment score\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# Get the sentiment score\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manalyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolarity_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# Return the sentiment score\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:269\u001B[0m, in \u001B[0;36mSentimentIntensityAnalyzer.polarity_scores\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m    266\u001B[0m         sentiments\u001B[38;5;241m.\u001B[39mappend(valence)\n\u001B[0;32m    267\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m--> 269\u001B[0m     sentiments \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentiment_valence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msentitext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msentiments\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m sentiments \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_but_check(words_and_emoticons, sentiments)\n\u001B[0;32m    273\u001B[0m valence_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_valence(sentiments, text)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:313\u001B[0m, in \u001B[0;36mSentimentIntensityAnalyzer.sentiment_valence\u001B[1;34m(self, valence, sentitext, item, i, sentiments)\u001B[0m\n\u001B[0;32m    311\u001B[0m         valence \u001B[38;5;241m=\u001B[39m valence \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m    312\u001B[0m         valence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_negation_check(valence, words_and_emoticons, start_i, i)\n\u001B[1;32m--> 313\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mstart_i\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m:\n\u001B[0;32m    314\u001B[0m             valence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_special_idioms_check(valence, words_and_emoticons, i)\n\u001B[0;32m    316\u001B[0m valence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_least_check(valence, words_and_emoticons, i)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "neutral = []\n",
    "compound = []\n",
    "\n",
    "\n",
    "\n",
    "begin = time.time() # timer for entire process\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(dataPlug.df['title']))):\n",
    "    start = time.time() # timer for each iteration\n",
    "\n",
    "\n",
    "    text = dataPlug.df['title'][i]\n",
    "    clean_text = squeeze.clean_text(text)\n",
    "\n",
    "\n",
    "    score = squeeze.sentiment_analysis(clean_text)\n",
    "    # Add scores to array\n",
    "    positive.append(score['pos'])\n",
    "    negative.append(score['neg'])\n",
    "    neutral.append(score['neu'])\n",
    "    compound.append(score['compound'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(f\"Completed {i} of {len(dataPlug.df['title'])} posts | {end - start:0.4f} seconds | {end - begin:0.4f} seconds total\")\n",
    "\n",
    "end = time.time() # end timer for each iteration\n",
    "print(f\"Sentiment analysis took {end - begin:0.4f} seconds total\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using DataFrame.insert() to add the sentiment columns to the dataframe\n",
    "dataPlug.df.insert(1, \"Compound_Sentiment\", compound, True)\n",
    "dataPlug.df.insert(1, \"Negative_Sentiment\", negative, True)\n",
    "dataPlug.df.insert(1, \"Neutral_Sentiment\", neutral, True)\n",
    "dataPlug.df.insert(1, \"Positive_Sentiment\", positive, True)\n",
    "print('Done!')\n",
    "\n",
    "display(dataPlug.df)\n",
    "dataPlug.df.to_csv('../data/all_posts_with_sentiment.csv')\n",
    "print(f'saved to ../data/all_posts_with_sentiment.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     title  \\\n0                                Whats going on with PLTR?   \n1        Need explanations on Level 2 data for GME, why...   \n2             XRT is being used as a laundry short machine   \n3                                                Airlines?   \n4                                               Buy TRXC ðŸš€   \n...                                                    ...   \n1118858  EBAY posts higher 1Q net income and revenue, s...   \n1118859  Anyone betting on VVUS and their potential app...   \n1118860  My poorly timed opening position for AAPL earn...   \n1118861         GOOG - beat estimates, price barely rises.   \n1118862         Earnings season is here.  Place your bets.   \n\n         Positive_Sentiment  Neutral_Sentiment  Negative_Sentiment  \\\n0                     0.000              1.000                 0.0   \n1                     0.000              1.000                 0.0   \n2                     0.000              1.000                 0.0   \n3                     0.000              1.000                 0.0   \n4                     0.000              1.000                 0.0   \n...                     ...                ...                 ...   \n1118858               0.000              1.000                 0.0   \n1118859               0.205              0.795                 0.0   \n1118860               0.000              1.000                 0.0   \n1118861               0.000              1.000                 0.0   \n1118862               0.000              1.000                 0.0   \n\n         Compound_Sentiment  score  num_comments  timestamp  \n0                    0.0000      1             2 2021-02-16  \n1                    0.0000      1             2 2021-02-16  \n2                    0.0000      1             2 2021-02-16  \n3                    0.0000      1             2 2021-02-16  \n4                    0.0000      1             2 2021-02-16  \n...                     ...    ...           ...        ...  \n1118858              0.0000      7             4 2012-04-19  \n1118859              0.4767      1             0 2012-04-17  \n1118860              0.0000     12            21 2012-04-16  \n1118861              0.0000      2             0 2012-04-12  \n1118862              0.0000     13            22 2012-04-11  \n\n[1118863 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Positive_Sentiment</th>\n      <th>Neutral_Sentiment</th>\n      <th>Negative_Sentiment</th>\n      <th>Compound_Sentiment</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Whats going on with PLTR?</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Need explanations on Level 2 data for GME, why...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XRT is being used as a laundry short machine</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Airlines?</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Buy TRXC ðŸš€</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2021-02-16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1118858</th>\n      <td>EBAY posts higher 1Q net income and revenue, s...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2012-04-19</td>\n    </tr>\n    <tr>\n      <th>1118859</th>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>0.205</td>\n      <td>0.795</td>\n      <td>0.0</td>\n      <td>0.4767</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2012-04-17</td>\n    </tr>\n    <tr>\n      <th>1118860</th>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>12</td>\n      <td>21</td>\n      <td>2012-04-16</td>\n    </tr>\n    <tr>\n      <th>1118861</th>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2012-04-12</td>\n    </tr>\n    <tr>\n      <th>1118862</th>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>13</td>\n      <td>22</td>\n      <td>2012-04-11</td>\n    </tr>\n  </tbody>\n</table>\n<p>1118863 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/all_posts_with_sentiment.csv')\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "df['title'] = df['title'].apply(lambda x: str(x))\n",
    "df['timestamp'] = df['timestamp'].astype('datetime64[ns]').dt.floor('D')\n",
    "display(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                        title      score  \\\ntimestamp                                                                  \n2012-04-11         Earnings season is here.  Place your bets.  13.000000   \n2012-04-12         GOOG - beat estimates, price barely rises.   2.000000   \n2012-04-16  My poorly timed opening position for AAPL earn...  12.000000   \n2012-04-17  Anyone betting on VVUS and their potential app...   1.000000   \n2012-04-19  After HGSI spikes 97%, will share price drop a...   5.500000   \n...                                                       ...        ...   \n2021-02-12  When you Can't Afford to Lose, Sell Options! +...   1.002569   \n2021-02-13  SatoshiSwap (SAS) is the future!!!!||Strategie...   1.000765   \n2021-02-14  Created a cliff for myself to jump off of||I w...   1.000337   \n2021-02-15  $EAT next up!||BNGO BNGO||Can yâ€™all bad mamaja...   1.011086   \n2021-02-16  Whats going on with PLTR?||Need explanations o...   1.599837   \n\n            num_comments  Positive_Sentiment  Negative_Sentiment  \\\ntimestamp                                                          \n2012-04-11     22.000000            0.000000            0.000000   \n2012-04-12      0.000000            0.000000            0.000000   \n2012-04-16     21.000000            0.000000            0.000000   \n2012-04-17      0.000000            0.205000            0.000000   \n2012-04-19      2.000000            0.082500            0.079000   \n...                  ...                 ...                 ...   \n2021-02-12     21.684764            0.133737            0.053982   \n2021-02-13     10.059153            0.140172            0.046565   \n2021-02-14     10.891326            0.139030            0.045846   \n2021-02-15     18.004751            0.128405            0.050436   \n2021-02-16      6.726161            0.132007            0.049172   \n\n            Neutral_Sentiment  Compound_Sentiment  \ntimestamp                                          \n2012-04-11           1.000000            0.000000  \n2012-04-12           1.000000            0.000000  \n2012-04-16           1.000000            0.000000  \n2012-04-17           0.795000            0.476700  \n2012-04-19           0.838500            0.012900  \n...                       ...                 ...  \n2021-02-12           0.809946            0.120769  \n2021-02-13           0.810966            0.135202  \n2021-02-14           0.812087            0.130886  \n2021-02-15           0.817675            0.110758  \n2021-02-16           0.816370            0.111608  \n\n[3020 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>Positive_Sentiment</th>\n      <th>Negative_Sentiment</th>\n      <th>Neutral_Sentiment</th>\n      <th>Compound_Sentiment</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-04-11</th>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>13.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2012-04-12</th>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2012-04-16</th>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>12.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2012-04-17</th>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.205000</td>\n      <td>0.000000</td>\n      <td>0.795000</td>\n      <td>0.476700</td>\n    </tr>\n    <tr>\n      <th>2012-04-19</th>\n      <td>After HGSI spikes 97%, will share price drop a...</td>\n      <td>5.500000</td>\n      <td>2.000000</td>\n      <td>0.082500</td>\n      <td>0.079000</td>\n      <td>0.838500</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-02-12</th>\n      <td>When you Can't Afford to Lose, Sell Options! +...</td>\n      <td>1.002569</td>\n      <td>21.684764</td>\n      <td>0.133737</td>\n      <td>0.053982</td>\n      <td>0.809946</td>\n      <td>0.120769</td>\n    </tr>\n    <tr>\n      <th>2021-02-13</th>\n      <td>SatoshiSwap (SAS) is the future!!!!||Strategie...</td>\n      <td>1.000765</td>\n      <td>10.059153</td>\n      <td>0.140172</td>\n      <td>0.046565</td>\n      <td>0.810966</td>\n      <td>0.135202</td>\n    </tr>\n    <tr>\n      <th>2021-02-14</th>\n      <td>Created a cliff for myself to jump off of||I w...</td>\n      <td>1.000337</td>\n      <td>10.891326</td>\n      <td>0.139030</td>\n      <td>0.045846</td>\n      <td>0.812087</td>\n      <td>0.130886</td>\n    </tr>\n    <tr>\n      <th>2021-02-15</th>\n      <td>$EAT next up!||BNGO BNGO||Can yâ€™all bad mamaja...</td>\n      <td>1.011086</td>\n      <td>18.004751</td>\n      <td>0.128405</td>\n      <td>0.050436</td>\n      <td>0.817675</td>\n      <td>0.110758</td>\n    </tr>\n    <tr>\n      <th>2021-02-16</th>\n      <td>Whats going on with PLTR?||Need explanations o...</td>\n      <td>1.599837</td>\n      <td>6.726161</td>\n      <td>0.132007</td>\n      <td>0.049172</td>\n      <td>0.816370</td>\n      <td>0.111608</td>\n    </tr>\n  </tbody>\n</table>\n<p>3020 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_func = {'title': list, 'score': 'mean', 'num_comments': 'mean', 'Positive_Sentiment': 'mean', 'Negative_Sentiment': 'mean', 'Neutral_Sentiment': 'mean', 'Compound_Sentiment': 'mean'}\n",
    "\n",
    "# Replace NaN values with 'NaN'\n",
    "#df['total_awards_received'] = df['total_awards_received'].fillna(0)\n",
    "# Group by date and aggregate\n",
    "df_new = df.groupby(df['timestamp']).aggregate(agg_func)\n",
    "\n",
    "# Join lists of titles, ids, urls, and bodies into one string per date to perform sentiment analysis.\n",
    "\n",
    "df_new['title'] = df_new['title'].apply(lambda x: '||'.join(x))\n",
    "\n",
    "\n",
    "display(df_new)\n",
    "dataPlug.df = df_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "      timestamp       Open       High      Low    Close  Adj Close     Volume  \\\n0    2012-04-11   5.330000   5.380000   5.2350   5.3175   3.603972   19562000   \n1    2012-04-12   5.325000   5.427500   5.3125   5.3900   3.653110    8414800   \n2    2012-04-16   5.325000   5.452500   5.2425   5.4250   3.676833   13710000   \n3    2012-04-17   5.455000   5.550000   5.4500   5.5375   3.753081   16022400   \n4    2012-04-19   5.562500   5.635000   5.5325   5.5725   3.776802   14128400   \n...         ...        ...        ...      ...      ...        ...        ...   \n2140 2021-02-08  18.102501  18.165001  14.5050  15.0000  15.000000  102749200   \n2141 2021-02-09  14.152500  14.250000  11.6300  12.5775  12.577500  107372400   \n2142 2021-02-10  12.692500  15.707500  11.6375  12.8000  12.800000  145820000   \n2143 2021-02-11  12.502500  13.830000  12.0550  12.7750  12.775000   52226800   \n2144 2021-02-12  12.687500  13.810000  12.0125  13.1000  13.100000   58293200   \n\n                                                  title      score  \\\n0            Earnings season is here.  Place your bets.  13.000000   \n1            GOOG - beat estimates, price barely rises.   2.000000   \n2     My poorly timed opening position for AAPL earn...  12.000000   \n3     Anyone betting on VVUS and their potential app...   1.000000   \n4     After HGSI spikes 97%, will share price drop a...   5.500000   \n...                                                 ...        ...   \n2140  Me on the RH||Can you Help me giving the name ...   1.085725   \n2141  Cindicator Capital Wants to Hire r/WallStreetB...   1.000829   \n2142  Why the fuck isnâ€™t anyone talking about then G...   6.014227   \n2143  Who loves a Pi ?||Does anyone know about Atlis...   1.207335   \n2144  When you Can't Afford to Lose, Sell Options! +...   1.002569   \n\n      num_comments  Positive_Sentiment  Negative_Sentiment  Neutral_Sentiment  \\\n0        22.000000            0.000000            0.000000           1.000000   \n1         0.000000            0.000000            0.000000           1.000000   \n2        21.000000            0.000000            0.000000           1.000000   \n3         0.000000            0.205000            0.000000           0.795000   \n4         2.000000            0.082500            0.079000           0.838500   \n...            ...                 ...                 ...                ...   \n2140     10.603988            0.152163            0.048261           0.797151   \n2141     13.947142            0.139888            0.048742           0.811039   \n2142     20.014591            0.152525            0.039616           0.805182   \n2143     17.038586            0.142902            0.045269           0.810214   \n2144     21.684764            0.133737            0.053982           0.809946   \n\n      Compound_Sentiment  \n0               0.000000  \n1               0.000000  \n2               0.000000  \n3               0.476700  \n4               0.012900  \n...                  ...  \n2140            0.147872  \n2141            0.129740  \n2142            0.163156  \n2143            0.138476  \n2144            0.120769  \n\n[2145 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>title</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>Positive_Sentiment</th>\n      <th>Negative_Sentiment</th>\n      <th>Neutral_Sentiment</th>\n      <th>Compound_Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-04-11</td>\n      <td>5.330000</td>\n      <td>5.380000</td>\n      <td>5.2350</td>\n      <td>5.3175</td>\n      <td>3.603972</td>\n      <td>19562000</td>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>13.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-04-12</td>\n      <td>5.325000</td>\n      <td>5.427500</td>\n      <td>5.3125</td>\n      <td>5.3900</td>\n      <td>3.653110</td>\n      <td>8414800</td>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-04-16</td>\n      <td>5.325000</td>\n      <td>5.452500</td>\n      <td>5.2425</td>\n      <td>5.4250</td>\n      <td>3.676833</td>\n      <td>13710000</td>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>12.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-04-17</td>\n      <td>5.455000</td>\n      <td>5.550000</td>\n      <td>5.4500</td>\n      <td>5.5375</td>\n      <td>3.753081</td>\n      <td>16022400</td>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.205000</td>\n      <td>0.000000</td>\n      <td>0.795000</td>\n      <td>0.476700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-04-19</td>\n      <td>5.562500</td>\n      <td>5.635000</td>\n      <td>5.5325</td>\n      <td>5.5725</td>\n      <td>3.776802</td>\n      <td>14128400</td>\n      <td>After HGSI spikes 97%, will share price drop a...</td>\n      <td>5.500000</td>\n      <td>2.000000</td>\n      <td>0.082500</td>\n      <td>0.079000</td>\n      <td>0.838500</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2140</th>\n      <td>2021-02-08</td>\n      <td>18.102501</td>\n      <td>18.165001</td>\n      <td>14.5050</td>\n      <td>15.0000</td>\n      <td>15.000000</td>\n      <td>102749200</td>\n      <td>Me on the RH||Can you Help me giving the name ...</td>\n      <td>1.085725</td>\n      <td>10.603988</td>\n      <td>0.152163</td>\n      <td>0.048261</td>\n      <td>0.797151</td>\n      <td>0.147872</td>\n    </tr>\n    <tr>\n      <th>2141</th>\n      <td>2021-02-09</td>\n      <td>14.152500</td>\n      <td>14.250000</td>\n      <td>11.6300</td>\n      <td>12.5775</td>\n      <td>12.577500</td>\n      <td>107372400</td>\n      <td>Cindicator Capital Wants to Hire r/WallStreetB...</td>\n      <td>1.000829</td>\n      <td>13.947142</td>\n      <td>0.139888</td>\n      <td>0.048742</td>\n      <td>0.811039</td>\n      <td>0.129740</td>\n    </tr>\n    <tr>\n      <th>2142</th>\n      <td>2021-02-10</td>\n      <td>12.692500</td>\n      <td>15.707500</td>\n      <td>11.6375</td>\n      <td>12.8000</td>\n      <td>12.800000</td>\n      <td>145820000</td>\n      <td>Why the fuck isnâ€™t anyone talking about then G...</td>\n      <td>6.014227</td>\n      <td>20.014591</td>\n      <td>0.152525</td>\n      <td>0.039616</td>\n      <td>0.805182</td>\n      <td>0.163156</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>2021-02-11</td>\n      <td>12.502500</td>\n      <td>13.830000</td>\n      <td>12.0550</td>\n      <td>12.7750</td>\n      <td>12.775000</td>\n      <td>52226800</td>\n      <td>Who loves a Pi ?||Does anyone know about Atlis...</td>\n      <td>1.207335</td>\n      <td>17.038586</td>\n      <td>0.142902</td>\n      <td>0.045269</td>\n      <td>0.810214</td>\n      <td>0.138476</td>\n    </tr>\n    <tr>\n      <th>2144</th>\n      <td>2021-02-12</td>\n      <td>12.687500</td>\n      <td>13.810000</td>\n      <td>12.0125</td>\n      <td>13.1000</td>\n      <td>13.100000</td>\n      <td>58293200</td>\n      <td>When you Can't Afford to Lose, Sell Options! +...</td>\n      <td>1.002569</td>\n      <td>21.684764</td>\n      <td>0.133737</td>\n      <td>0.053982</td>\n      <td>0.809946</td>\n      <td>0.120769</td>\n    </tr>\n  </tbody>\n</table>\n<p>2145 rows Ã— 14 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../data/mergedDF.csv\n"
     ]
    }
   ],
   "source": [
    "dataPlug.get_price_dataframe()\n",
    "dataPlug.merge_dataframes()\n",
    "display(dataPlug.mergedDF)\n",
    "dataPlug.mergedDF.to_csv('../data/mergedDF.csv')\n",
    "print(f'saved to ../data/mergedDF.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Run if you want to load the dataframe from a file to avoid re-running sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# If you want to load the mergedDF from a csv file\n",
    "dataPlug.mergedDF = pd.read_csv('../data/mergedDF.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "prices = dataPlug.mergedDF['High'].tolist()\n",
    "y = []\n",
    "for i in prices:\n",
    "        y.append(float(i))\n",
    "volume_y = dataPlug.mergedDF['Volume'].tolist()\n",
    "\n",
    "\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Open', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('High', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Low', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Close', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Adj Close', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Volume', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                                              title  \\\n0              0         Earnings season is here.  Place your bets.   \n1              1         GOOG - beat estimates, price barely rises.   \n2              2  My poorly timed opening position for AAPL earn...   \n3              3  Anyone betting on VVUS and their potential app...   \n4              4  After HGSI spikes 97%, will share price drop a...   \n...          ...                                                ...   \n2140        2140  Me on the RH||Can you Help me giving the name ...   \n2141        2141  Cindicator Capital Wants to Hire r/WallStreetB...   \n2142        2142  Why the fuck isnâ€™t anyone talking about then G...   \n2143        2143  Who loves a Pi ?||Does anyone know about Atlis...   \n2144        2144  When you Can't Afford to Lose, Sell Options! +...   \n\n          score  num_comments  Positive_Sentiment  Negative_Sentiment  \\\n0     13.000000     22.000000            0.000000            0.000000   \n1      2.000000      0.000000            0.000000            0.000000   \n2     12.000000     21.000000            0.000000            0.000000   \n3      1.000000      0.000000            0.205000            0.000000   \n4      5.500000      2.000000            0.082500            0.079000   \n...         ...           ...                 ...                 ...   \n2140   1.085725     10.603988            0.152163            0.048261   \n2141   1.000829     13.947142            0.139888            0.048742   \n2142   6.014227     20.014591            0.152525            0.039616   \n2143   1.207335     17.038586            0.142902            0.045269   \n2144   1.002569     21.684764            0.133737            0.053982   \n\n      Neutral_Sentiment  Compound_Sentiment  \n0              1.000000            0.000000  \n1              1.000000            0.000000  \n2              1.000000            0.000000  \n3              0.795000            0.476700  \n4              0.838500            0.012900  \n...                 ...                 ...  \n2140           0.797151            0.147872  \n2141           0.811039            0.129740  \n2142           0.805182            0.163156  \n2143           0.810214            0.138476  \n2144           0.809946            0.120769  \n\n[2145 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>Positive_Sentiment</th>\n      <th>Negative_Sentiment</th>\n      <th>Neutral_Sentiment</th>\n      <th>Compound_Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Earnings season is here.  Place your bets.</td>\n      <td>13.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>GOOG - beat estimates, price barely rises.</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>My poorly timed opening position for AAPL earn...</td>\n      <td>12.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Anyone betting on VVUS and their potential app...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.205000</td>\n      <td>0.000000</td>\n      <td>0.795000</td>\n      <td>0.476700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>After HGSI spikes 97%, will share price drop a...</td>\n      <td>5.500000</td>\n      <td>2.000000</td>\n      <td>0.082500</td>\n      <td>0.079000</td>\n      <td>0.838500</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2140</th>\n      <td>2140</td>\n      <td>Me on the RH||Can you Help me giving the name ...</td>\n      <td>1.085725</td>\n      <td>10.603988</td>\n      <td>0.152163</td>\n      <td>0.048261</td>\n      <td>0.797151</td>\n      <td>0.147872</td>\n    </tr>\n    <tr>\n      <th>2141</th>\n      <td>2141</td>\n      <td>Cindicator Capital Wants to Hire r/WallStreetB...</td>\n      <td>1.000829</td>\n      <td>13.947142</td>\n      <td>0.139888</td>\n      <td>0.048742</td>\n      <td>0.811039</td>\n      <td>0.129740</td>\n    </tr>\n    <tr>\n      <th>2142</th>\n      <td>2142</td>\n      <td>Why the fuck isnâ€™t anyone talking about then G...</td>\n      <td>6.014227</td>\n      <td>20.014591</td>\n      <td>0.152525</td>\n      <td>0.039616</td>\n      <td>0.805182</td>\n      <td>0.163156</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>2143</td>\n      <td>Who loves a Pi ?||Does anyone know about Atlis...</td>\n      <td>1.207335</td>\n      <td>17.038586</td>\n      <td>0.142902</td>\n      <td>0.045269</td>\n      <td>0.810214</td>\n      <td>0.138476</td>\n    </tr>\n    <tr>\n      <th>2144</th>\n      <td>2144</td>\n      <td>When you Can't Afford to Lose, Sell Options! +...</td>\n      <td>1.002569</td>\n      <td>21.684764</td>\n      <td>0.133737</td>\n      <td>0.053982</td>\n      <td>0.809946</td>\n      <td>0.120769</td>\n    </tr>\n  </tbody>\n</table>\n<p>2145 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('timestamp', axis=1)\n",
    "display(dataPlug.mergedDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "          score  num_comments  Positive_Sentiment  Negative_Sentiment  \\\n0     13.000000     22.000000            0.000000            0.000000   \n1      2.000000      0.000000            0.000000            0.000000   \n2     12.000000     21.000000            0.000000            0.000000   \n3      1.000000      0.000000            0.205000            0.000000   \n4      5.500000      2.000000            0.082500            0.079000   \n...         ...           ...                 ...                 ...   \n2140   1.085725     10.603988            0.152163            0.048261   \n2141   1.000829     13.947142            0.139888            0.048742   \n2142   6.014227     20.014591            0.152525            0.039616   \n2143   1.207335     17.038586            0.142902            0.045269   \n2144   1.002569     21.684764            0.133737            0.053982   \n\n      Neutral_Sentiment  Compound_Sentiment  \n0              1.000000            0.000000  \n1              1.000000            0.000000  \n2              1.000000            0.000000  \n3              0.795000            0.476700  \n4              0.838500            0.012900  \n...                 ...                 ...  \n2140           0.797151            0.147872  \n2141           0.811039            0.129740  \n2142           0.805182            0.163156  \n2143           0.810214            0.138476  \n2144           0.809946            0.120769  \n\n[2145 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>Positive_Sentiment</th>\n      <th>Negative_Sentiment</th>\n      <th>Neutral_Sentiment</th>\n      <th>Compound_Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.205000</td>\n      <td>0.000000</td>\n      <td>0.795000</td>\n      <td>0.476700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.500000</td>\n      <td>2.000000</td>\n      <td>0.082500</td>\n      <td>0.079000</td>\n      <td>0.838500</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2140</th>\n      <td>1.085725</td>\n      <td>10.603988</td>\n      <td>0.152163</td>\n      <td>0.048261</td>\n      <td>0.797151</td>\n      <td>0.147872</td>\n    </tr>\n    <tr>\n      <th>2141</th>\n      <td>1.000829</td>\n      <td>13.947142</td>\n      <td>0.139888</td>\n      <td>0.048742</td>\n      <td>0.811039</td>\n      <td>0.129740</td>\n    </tr>\n    <tr>\n      <th>2142</th>\n      <td>6.014227</td>\n      <td>20.014591</td>\n      <td>0.152525</td>\n      <td>0.039616</td>\n      <td>0.805182</td>\n      <td>0.163156</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>1.207335</td>\n      <td>17.038586</td>\n      <td>0.142902</td>\n      <td>0.045269</td>\n      <td>0.810214</td>\n      <td>0.138476</td>\n    </tr>\n    <tr>\n      <th>2144</th>\n      <td>1.002569</td>\n      <td>21.684764</td>\n      <td>0.133737</td>\n      <td>0.053982</td>\n      <td>0.809946</td>\n      <td>0.120769</td>\n    </tr>\n  </tbody>\n</table>\n<p>2145 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataPlug.mergedDF = dataPlug.mergedDF.drop('title', axis=1)\n",
    "dataPlug.mergedDF = dataPlug.mergedDF.drop('Unnamed: 0', axis=1)\n",
    "display(dataPlug.mergedDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "X = dataPlug.mergedDF\n",
    "# split data into test and training sets\n",
    "X_train, X_test, y_train_list, y_test_list = train_test_split(X, y, test_size=0.5, random_state=3)\n",
    "y_train = []\n",
    "for item in y_train_list:\n",
    "    y_train.append(int(item))\n",
    "\n",
    "y_test = []\n",
    "for item in y_test_list:\n",
    "    y_test.append(int(item))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "BernoulliNB()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest regression\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.15671641791044777\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# predict labels for training and test sets\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training score:\", train_score)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.18      1.00      0.31       159\n",
      "           2       0.00      0.00      0.00        47\n",
      "           3       0.00      0.00      0.00       113\n",
      "           4       0.00      0.00      0.00       107\n",
      "           5       0.00      0.00      0.00       100\n",
      "           6       0.12      0.03      0.05       119\n",
      "           7       0.00      0.00      0.00        82\n",
      "           8       0.00      0.00      0.00        42\n",
      "           9       0.17      0.23      0.20        77\n",
      "          10       0.18      0.08      0.11        98\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       1.00      0.03      0.05        38\n",
      "          13       0.09      0.09      0.09        11\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18      1073\n",
      "   macro avg       0.09      0.08      0.04      1073\n",
      "weighted avg       0.10      0.18      0.08      1073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackk\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jackk\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jackk\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['High']\n",
    "print(classification_report(y_test, y_test_pred.astype('int')))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
